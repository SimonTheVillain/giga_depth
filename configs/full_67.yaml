training:
  name: full_67
  batch_size: 2
  learning_rate: 4.0
  lr_scales: [1.0, 0.5, 0.25, 0.12, 0.01]
  momentum: 0.9
  weight_decay: 1e-5
  alpha_reg: [500, 1000, 2000, 2000, 2000]
  alpha_reg_photometric: [1e-2, 1e-2, 1e-1, 1e-1, 1]
  alpha_reg_conv: [1, 1, 1, 1, 1]
  alpha_sigma: [1e-2, 1e-2, 1e-1, 1e-1, 1]
  edge_weight: [0, 1, 2, 4, 20]
  sigma_mode: automask
  gpu_list: [0]
  overall_steps: 70000 # todo: maybe don't use this
  key_steps: [ 20000, 30000, 40000, 50000 ] # todo: maybe don't use this
  epochs: 13
  key_epochs: [ 2, 4, 6, 8 ]
  key_step_scale: 2
  half_precision: False

dataset:
  path: /media/simon/WD/datasets_raw
  is_npy: False
  workers: 8
  tgt_res: [ 1216, 896 ]
  vertical_jitter: 4
  downsample_output: True
  dataset_type: structure_core_combo
  slice_in:
    start: 0
    height: 896
  slice_out:
    start: 0
    height: 448

backbone:
  load_file: "trained_models/full_66_j4_backbone_chk.pt"
  name: Backbone3Sliced
  input_channels: 2
  lines: 896
  slices: 4
  channels: [16, 32, 64]
  channels2: [64, 64, 64, 64]
  norm: batch
  local_contrast_norm: False

regressor:
  load_file: "trained_models/full_66_j4_regressor_chk.pt"
  name: Regv3
  ch_in: 64
  lines: 448
  bb: []
  classes: [16, 14, 12]
  padding: [0, 1, 2]
  class_bb: [[32], [32], [32]]
  superclasses: 336
  ch_reg: [32]
  msk: [16, 8]
  regress_neighbours: 1
  reg_line_div: 4
  c3_line_div: 8 #8 might be over the top but lets see how we fare with this!
  close_far_separation: True
  sigma_mode: conv

regressor_conv:
  load_file: ""
  name: conv_reg
  layers: [64, 128, 128, 512, 128] #[64, 128, 128, 512, 128]
  layers_msk: [64, 32, 16] #[64, 128, 64, 64]
  slices: 4
  vertical_fourier_encoding: 8